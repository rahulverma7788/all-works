{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "sentiment2bertcopy.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "18dc4e48b6a84761bba835e0d381c024": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b1d98bb5e854474bb8656a719bfdf78d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_52c748f41807486db079ef5d3b7ec7c7",
              "IPY_MODEL_69104c4f5bbe4a818964e05f29493b5e"
            ]
          }
        },
        "b1d98bb5e854474bb8656a719bfdf78d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "52c748f41807486db079ef5d3b7ec7c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f35ed61ebc44450abe4a96457bad026a",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6f1493d50bf04a0b8b23d1171010fdfd"
          }
        },
        "69104c4f5bbe4a818964e05f29493b5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cc0ee68cd16c4d5fbb800dd0fcec6c7c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 806kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_60b5049785ef4f94b09ceb05da7a79ea"
          }
        },
        "f35ed61ebc44450abe4a96457bad026a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6f1493d50bf04a0b8b23d1171010fdfd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cc0ee68cd16c4d5fbb800dd0fcec6c7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "60b5049785ef4f94b09ceb05da7a79ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0ec9604b63ed49ec98d8e3727ab5da00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5dbe13ade9d84e259ae2e1efe7ba7aa1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_71418db7c9594c3a850bd41a49e391e6",
              "IPY_MODEL_bed27af1d115470e9e2d85633e4c1ad0"
            ]
          }
        },
        "5dbe13ade9d84e259ae2e1efe7ba7aa1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "71418db7c9594c3a850bd41a49e391e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_73b575db802f43cc829f36f8e16a5bbf",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a763952721ba4fb9846a26432e6a2f8a"
          }
        },
        "bed27af1d115470e9e2d85633e4c1ad0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_11f9d431fe004b179351e78ac35ca147",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 781B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7f3ba99dc0444f6a92d7355153a6e978"
          }
        },
        "73b575db802f43cc829f36f8e16a5bbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a763952721ba4fb9846a26432e6a2f8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "11f9d431fe004b179351e78ac35ca147": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7f3ba99dc0444f6a92d7355153a6e978": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5b1c586150044586833c17dd987070cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8a9a56308c524038b86dada8fd2b6aa0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c8a00553362a4001a84120689c9196d0",
              "IPY_MODEL_fcfb776c97dc4f189977bbc412fbb5ce"
            ]
          }
        },
        "8a9a56308c524038b86dada8fd2b6aa0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c8a00553362a4001a84120689c9196d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b896efaf7de747439316e093ab16d81d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5bb5b86bcbe345f88e2f83af101abd6e"
          }
        },
        "fcfb776c97dc4f189977bbc412fbb5ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_29de9f624c3c47538361c94526a7aee3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:07&lt;00:00, 57.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d39719363a80471fafac2adff9450ecd"
          }
        },
        "b896efaf7de747439316e093ab16d81d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5bb5b86bcbe345f88e2f83af101abd6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "29de9f624c3c47538361c94526a7aee3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d39719363a80471fafac2adff9450ecd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0T08B9Kd4jE",
        "outputId": "e04a3721-7359-4fff-a12f-5f8f108d5243"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hscFXOmseBA2",
        "outputId": "6f944c0c-08c8-40c3-9a7a-a87ab8155657"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import textblob\n",
        "from textblob import TextBlob, Word\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "table = str.maketrans('', '', string.punctuation)\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "from nltk.stem import wordnet\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "word_lem = WordNetLemmatizer()\n",
        "from textblob import TextBlob\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.text import one_hot\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSAFUIbN-z7O"
      },
      "source": [
        "def read_dataset():\n",
        "    data = pd.read_csv(r\"/content/drive/MyDrive/Data Set Suicidal/unprocessed.csv\", sep = '\\t', header = None)\n",
        "    data.columns = ['sentence', 'labels']\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0h_rsbNI-6Ke"
      },
      "source": [
        "def sample_data(data, sample_value):\n",
        "    data = data[:][:sample_value]\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vG3eK1E-9tc",
        "outputId": "bd59b55b-6c11-44a7-daf4-bc5c70b23bf8"
      },
      "source": [
        "print(read_dataset())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                 sentence  labels\n",
            "0       I’m having anxiety right now and it’s not goin...       0\n",
            "1       Its been a hard hard week for me, i decided to...       0\n",
            "2       I was extremely suicidal 8 months ago. I reali...       1\n",
            "3       After a long and terrible relationship and not...       0\n",
            "4       Specifically against Yunkai and Astapor. Two c...       0\n",
            "...                                                   ...     ...\n",
            "207417  The love of my life is slowly drifting away fr...       1\n",
            "207418  Because of all the shit that is happening in t...       1\n",
            "207419  Kind of an oddball question, but for anybody w...       1\n",
            "207420  The thought of taking exams is triggering suic...       1\n",
            "207421  I havent been clinically/psychologically diagn...       0\n",
            "\n",
            "[207422 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mlqqqob2-_1Y"
      },
      "source": [
        "data = read_dataset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYmmf3Ke_EZD",
        "outputId": "27e3504c-f595-436b-ce86-de6f65be5545"
      },
      "source": [
        "print(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                 sentence  labels\n",
            "0       I’m having anxiety right now and it’s not goin...       0\n",
            "1       Its been a hard hard week for me, i decided to...       0\n",
            "2       I was extremely suicidal 8 months ago. I reali...       1\n",
            "3       After a long and terrible relationship and not...       0\n",
            "4       Specifically against Yunkai and Astapor. Two c...       0\n",
            "...                                                   ...     ...\n",
            "207417  The love of my life is slowly drifting away fr...       1\n",
            "207418  Because of all the shit that is happening in t...       1\n",
            "207419  Kind of an oddball question, but for anybody w...       1\n",
            "207420  The thought of taking exams is triggering suic...       1\n",
            "207421  I havent been clinically/psychologically diagn...       0\n",
            "\n",
            "[207422 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnvQhfAI_GmX"
      },
      "source": [
        "def avg_word_len (sentence):\n",
        "    words = sentence.split()\n",
        "    avg_len = sum(len(word) for word in words)/len(words)\n",
        "    return avg_len\n",
        "\n",
        "def extract_ngrams(data, num):\n",
        "    '''\n",
        "    Function to generate n-grams from sentences\n",
        "    '''\n",
        "    n_grams = TextBlob(data).ngrams(num)\n",
        "    return [ ' '.join(grams) for grams in n_grams]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "nNrGkv_1_Jap",
        "outputId": "48f8fc2c-1d8e-4108-ecc3-74c5c485ff43"
      },
      "source": [
        "print(data.shape)\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(207422, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I’m having anxiety right now and it’s not goin...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Its been a hard hard week for me, i decided to...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I was extremely suicidal 8 months ago. I reali...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>After a long and terrible relationship and not...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Specifically against Yunkai and Astapor. Two c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentence  labels\n",
              "0  I’m having anxiety right now and it’s not goin...       0\n",
              "1  Its been a hard hard week for me, i decided to...       0\n",
              "2  I was extremely suicidal 8 months ago. I reali...       1\n",
              "3  After a long and terrible relationship and not...       0\n",
              "4  Specifically against Yunkai and Astapor. Two c...       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "xVR_-Z5t_MlB",
        "outputId": "7827d3d5-68b5-4f68-d6cd-c70d5f0f575b"
      },
      "source": [
        "data['char_count'] = data['sentence'].str.len()\n",
        "df_train_sort_charcount = data.sort_values(by='char_count', ascending=False)\n",
        "df_train_sort_charcount[['sentence', 'char_count']].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>char_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>95803</th>\n",
              "      <td>https://www.evernote.com/shard/s405/sh/cb9e84c...</td>\n",
              "      <td>39883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52839</th>\n",
              "      <td>Felicia: [Part 1](https://www.reddit.com/r/nos...</td>\n",
              "      <td>39366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117650</th>\n",
              "      <td>Some may remember me. I was asked what’s going...</td>\n",
              "      <td>37055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117543</th>\n",
              "      <td>Microwave, Penicillin, chocolate chip cookies,...</td>\n",
              "      <td>36819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91805</th>\n",
              "      <td>\\[Before I post this: this turned out way long...</td>\n",
              "      <td>36788</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 sentence  char_count\n",
              "95803   https://www.evernote.com/shard/s405/sh/cb9e84c...       39883\n",
              "52839   Felicia: [Part 1](https://www.reddit.com/r/nos...       39366\n",
              "117650  Some may remember me. I was asked what’s going...       37055\n",
              "117543  Microwave, Penicillin, chocolate chip cookies,...       36819\n",
              "91805   \\[Before I post this: this turned out way long...       36788"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "522OBglH_P-2",
        "outputId": "fe86caee-3e08-4b48-bfba-4737e353c2a9"
      },
      "source": [
        "data['word_count'] = data['sentence'].apply(lambda x: len(str(x).split(\" \")))\n",
        "df_train_sort_wordcount = data.sort_values(by='word_count', ascending=False)\n",
        "df_train_sort_wordcount[['sentence','word_count']].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>word_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>95803</th>\n",
              "      <td>https://www.evernote.com/shard/s405/sh/cb9e84c...</td>\n",
              "      <td>7115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117650</th>\n",
              "      <td>Some may remember me. I was asked what’s going...</td>\n",
              "      <td>7027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91805</th>\n",
              "      <td>\\[Before I post this: this turned out way long...</td>\n",
              "      <td>6707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>186512</th>\n",
              "      <td>I’m an avid explorer. For as long as I can rem...</td>\n",
              "      <td>6518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117543</th>\n",
              "      <td>Microwave, Penicillin, chocolate chip cookies,...</td>\n",
              "      <td>6512</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 sentence  word_count\n",
              "95803   https://www.evernote.com/shard/s405/sh/cb9e84c...        7115\n",
              "117650  Some may remember me. I was asked what’s going...        7027\n",
              "91805   \\[Before I post this: this turned out way long...        6707\n",
              "186512  I’m an avid explorer. For as long as I can rem...        6518\n",
              "117543  Microwave, Penicillin, chocolate chip cookies,...        6512"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcm-VBvy_Sfd",
        "outputId": "e3a7217b-da4d-4a52-9191-66e1b1acbc3e"
      },
      "source": [
        "data = data['sentence'][0]\n",
        "print(\"1-gram: \", extract_ngrams(data, 1))\n",
        "print(\"2-gram: \", extract_ngrams(data, 2))\n",
        "print(\"3-gram: \", extract_ngrams(data, 3))\n",
        "print(\"4-gram: \", extract_ngrams(data, 4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1-gram:  ['I', '’', 'm', 'having', 'anxiety', 'right', 'now', 'and', 'it', '’', 's', 'not', 'going', 'away', 'it', 'didn', '’', 't', 'work', 'to', 'eat', 'I', '’', 'm', 'so', 'worried', 'about', 'getting', 'sick', 'What', 'can', 'I', 'do']\n",
            "2-gram:  ['I ’', '’ m', 'm having', 'having anxiety', 'anxiety right', 'right now', 'now and', 'and it', 'it ’', '’ s', 's not', 'not going', 'going away', 'away it', 'it didn', 'didn ’', '’ t', 't work', 'work to', 'to eat', 'eat I', 'I ’', '’ m', 'm so', 'so worried', 'worried about', 'about getting', 'getting sick', 'sick What', 'What can', 'can I', 'I do']\n",
            "3-gram:  ['I ’ m', '’ m having', 'm having anxiety', 'having anxiety right', 'anxiety right now', 'right now and', 'now and it', 'and it ’', 'it ’ s', '’ s not', 's not going', 'not going away', 'going away it', 'away it didn', 'it didn ’', 'didn ’ t', '’ t work', 't work to', 'work to eat', 'to eat I', 'eat I ’', 'I ’ m', '’ m so', 'm so worried', 'so worried about', 'worried about getting', 'about getting sick', 'getting sick What', 'sick What can', 'What can I', 'can I do']\n",
            "4-gram:  ['I ’ m having', '’ m having anxiety', 'm having anxiety right', 'having anxiety right now', 'anxiety right now and', 'right now and it', 'now and it ’', 'and it ’ s', 'it ’ s not', '’ s not going', 's not going away', 'not going away it', 'going away it didn', 'away it didn ’', 'it didn ’ t', 'didn ’ t work', '’ t work to', 't work to eat', 'work to eat I', 'to eat I ’', 'eat I ’ m', 'I ’ m so', '’ m so worried', 'm so worried about', 'so worried about getting', 'worried about getting sick', 'about getting sick What', 'getting sick What can', 'sick What can I', 'What can I do']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWwDZ08M_Vmt"
      },
      "source": [
        "def convert_to_string (df_train):\n",
        "    for i in range(len(df_train)):\n",
        "        df_train['sentence'][i] = str(df_train['sentence'][i])\n",
        "    return data\n",
        "\n",
        "def data_processing(data):\n",
        "    for i in range(len(data)):\n",
        "        # Remove Excape Sequences\n",
        "        sentence = remove_excape_sequesces(data['sentence'][i])\n",
        "        # Remove Links\n",
        "        sentence = remove_links(sentence)\n",
        "        # Forming the final paragraphs\n",
        "        senetnce = form_paragraph(sentence)\n",
        "        # Perform further NLP processing\n",
        "        sentence = apply_NLP(sentence)\n",
        "\n",
        "        data['sentence'][i] = sentence\n",
        "    return data\n",
        "\n",
        "def apply_NLP (sentence):\n",
        "    sentences = sentence.split(sep = '.')\n",
        "    for i in range(len(sentences)):\n",
        "        # Tokenize the words\n",
        "        tokens = word_tokenize(sentences[i])\n",
        "        tokens = [word.lower() for word in tokens]\n",
        "        # Remove puntuations\n",
        "        no_punctuations = [word.translate(table) for word in tokens]\n",
        "        # Remove all non-alphabetic characters.\n",
        "        words = [word for word in no_punctuations if word.isalpha()]\n",
        "        # Remove Stop words and convert the sentence to its base form\n",
        "        words = [word_lem.lemmatize(w) for w in words if not w in stop_words]\n",
        "        sentences[i] = \" \".join(words)\n",
        "    sentence = \" .\".join(sentences)\n",
        "    return sentence+\".\"\n",
        "\n",
        "def remove_excape_sequesces (sentence):\n",
        "    excape_sequences = ['\\n', '\\t', '\\r', '\\\\', '\\a', '\\f', '\\o', '\\v', '\\b', '\\\"', '\\'', '\\newline']\n",
        "    temp = \"\"\n",
        "    sentence = str(sentence)\n",
        "    for i in sentence:\n",
        "        if i in excape_sequences:\n",
        "            continue\n",
        "        temp += i\n",
        "    return temp\n",
        "\n",
        "def remove_links (sentence):\n",
        "    comment = sentence.split(sep = \" \")\n",
        "    for word in comment:\n",
        "        if ('http' in word) or ('www' in word) or ('https' in word) or (len(word) == 0):\n",
        "            comment.remove(word)\n",
        "    sentence = \" \".join(comment)\n",
        "    return sentence\n",
        "\n",
        "def form_paragraph (sentence):\n",
        "    temp = nltk.sent_tokenize(sentence)\n",
        "    for index in range(len(temp)):\n",
        "        temp[index] = temp[index].replace('.', ' ')\n",
        "    for index in range(len(temp)):\n",
        "        d = []\n",
        "        k = temp[index].split(sep = ' ')\n",
        "        for z in range(len(k)):\n",
        "            if len(k[z]) > 0:\n",
        "                d.append(k[z]) \n",
        "        s = ''\n",
        "        for j in range(len(d)):\n",
        "            s = s + ' ' + d[j].strip()\n",
        "        temp[index] = s.strip()      \n",
        "    sentence = '. '.join(temp).lower()\n",
        "    return sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "id": "FZ9Ikbvw_Z1F",
        "outputId": "ecc8eafd-228e-4a1e-b024-8f4cadd8af65"
      },
      "source": [
        "data = read_dataset()\n",
        "data = sample_data(data, 200000)\n",
        "data = convert_to_string(data)\n",
        "data = data_processing(data)\n",
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>anxiety right going away . . .work eat . . .wo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hard hard week decided go get happy drink orde...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>extremely suicidal month ago .realized ive rui...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>long terrible relationship going school anxiet...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>specifically yunkai astapor .two city full inn...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2595</th>\n",
              "      <td>im scared .scared .want die want die make sens...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2596</th>\n",
              "      <td>whatever silly mean everything monty python ba...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2597</th>\n",
              "      <td>frozen e menace pour le royaumela franchise de...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2598</th>\n",
              "      <td>connected iphone using bluetooth everything se...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2599</th>\n",
              "      <td>basically life feel like .feel tired foggy unm...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2600 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               sentence  labels\n",
              "0     anxiety right going away . . .work eat . . .wo...       0\n",
              "1     hard hard week decided go get happy drink orde...       0\n",
              "2     extremely suicidal month ago .realized ive rui...       1\n",
              "3     long terrible relationship going school anxiet...       0\n",
              "4     specifically yunkai astapor .two city full inn...       0\n",
              "...                                                 ...     ...\n",
              "2595  im scared .scared .want die want die make sens...       0\n",
              "2596  whatever silly mean everything monty python ba...       0\n",
              "2597  frozen e menace pour le royaumela franchise de...       0\n",
              "2598  connected iphone using bluetooth everything se...       0\n",
              "2599  basically life feel like .feel tired foggy unm...       0\n",
              "\n",
              "[2600 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWFMIELG_hMQ",
        "outputId": "fda3b6dd-2b2c-463b-eda8-e169dc901159"
      },
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfJu14I7_loj",
        "outputId": "11a467c7-fd38-4c7c-e24a-e78e556e550b"
      },
      "source": [
        "import torch\n",
        "if torch.cuda.is_available():    \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikxEvvaJ_orL",
        "outputId": "d3f42e95-921a-4ce4-9c07-6592debb9b91"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/54/5ca07ec9569d2f232f3166de5457b63943882f7950ddfcc887732fc7fb23/transformers-4.3.3-py3-none-any.whl (1.9MB)\n",
            "\r\u001b[K     |▏                               | 10kB 25.8MB/s eta 0:00:01\r\u001b[K     |▍                               | 20kB 15.2MB/s eta 0:00:01\r\u001b[K     |▌                               | 30kB 13.2MB/s eta 0:00:01\r\u001b[K     |▊                               | 40kB 12.8MB/s eta 0:00:01\r\u001b[K     |▉                               | 51kB 7.6MB/s eta 0:00:01\r\u001b[K     |█                               | 61kB 8.9MB/s eta 0:00:01\r\u001b[K     |█▏                              | 71kB 9.2MB/s eta 0:00:01\r\u001b[K     |█▍                              | 81kB 9.3MB/s eta 0:00:01\r\u001b[K     |█▌                              | 92kB 9.6MB/s eta 0:00:01\r\u001b[K     |█▊                              | 102kB 7.8MB/s eta 0:00:01\r\u001b[K     |██                              | 112kB 7.8MB/s eta 0:00:01\r\u001b[K     |██                              | 122kB 7.8MB/s eta 0:00:01\r\u001b[K     |██▎                             | 133kB 7.8MB/s eta 0:00:01\r\u001b[K     |██▍                             | 143kB 7.8MB/s eta 0:00:01\r\u001b[K     |██▋                             | 153kB 7.8MB/s eta 0:00:01\r\u001b[K     |██▊                             | 163kB 7.8MB/s eta 0:00:01\r\u001b[K     |███                             | 174kB 7.8MB/s eta 0:00:01\r\u001b[K     |███                             | 184kB 7.8MB/s eta 0:00:01\r\u001b[K     |███▎                            | 194kB 7.8MB/s eta 0:00:01\r\u001b[K     |███▌                            | 204kB 7.8MB/s eta 0:00:01\r\u001b[K     |███▋                            | 215kB 7.8MB/s eta 0:00:01\r\u001b[K     |███▉                            | 225kB 7.8MB/s eta 0:00:01\r\u001b[K     |████                            | 235kB 7.8MB/s eta 0:00:01\r\u001b[K     |████▏                           | 245kB 7.8MB/s eta 0:00:01\r\u001b[K     |████▎                           | 256kB 7.8MB/s eta 0:00:01\r\u001b[K     |████▌                           | 266kB 7.8MB/s eta 0:00:01\r\u001b[K     |████▋                           | 276kB 7.8MB/s eta 0:00:01\r\u001b[K     |████▉                           | 286kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████                           | 296kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 307kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 317kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 327kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 337kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 348kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 358kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 368kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 378kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 389kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 399kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████                         | 409kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████                         | 419kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 430kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 440kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 450kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 460kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 471kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 481kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 491kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 501kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 512kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 522kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████                       | 532kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 542kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 552kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 563kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 573kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 583kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 593kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 604kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 614kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 624kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 634kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 645kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 655kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 665kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 675kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 686kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 696kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 706kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 716kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 727kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 737kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 747kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 757kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 768kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 778kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 788kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 798kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 808kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 819kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 829kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 839kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 849kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 860kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 870kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 880kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 890kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 901kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 911kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 921kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 931kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████                | 942kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████                | 952kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 962kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 972kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 983kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 993kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.0MB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.0MB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 1.0MB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 1.0MB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 1.0MB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 1.1MB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.1MB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 1.1MB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 1.1MB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 1.1MB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 1.1MB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 1.1MB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.1MB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 1.1MB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 1.1MB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 1.2MB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 1.2MB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 1.2MB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.2MB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 1.2MB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 1.2MB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 1.2MB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 1.2MB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.2MB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.2MB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.3MB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.3MB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.3MB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.3MB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.3MB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.3MB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.3MB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 1.3MB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.3MB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.4MB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.4MB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.4MB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.4MB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.4MB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.4MB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.4MB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.4MB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.4MB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.4MB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.5MB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.5MB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.5MB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.5MB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.5MB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.5MB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.5MB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.5MB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.5MB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.5MB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.6MB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.6MB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.6MB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.6MB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.6MB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.6MB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.6MB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.6MB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.6MB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.6MB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.7MB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.7MB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.7MB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.7MB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.7MB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.7MB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.7MB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.7MB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.7MB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.8MB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.8MB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.8MB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.8MB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.8MB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.8MB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.8MB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.8MB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.8MB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.8MB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.9MB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.9MB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.9MB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.9MB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.9MB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.9MB 7.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/23/2ddc317b2121117bf34dd00f5b0de194158f2a44ee2bf5e47c7166878a97/tokenizers-0.10.1-cp37-cp37m-manylinux2010_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 22.6MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 52.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=86587ce7b97746a061003845293f0b5c1a947456583ca1090e180dd4c089b187\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.10.1 transformers-4.3.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDPZVJsE_sD1",
        "outputId": "57b5de77-ca23-4fa7-8627-41dcfaacb8ef"
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp37-none-any.whl size=9681 sha256=a6050b51bdec1e7f4c6bc4c1388c7ed549352264efb626a52007cfda99b929f5\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "IwnUIXcR_u6M",
        "outputId": "3f8f442c-96a5-4740-9b6f-8eca2c2b5171"
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>anxiety right going away . . .work eat . . .wo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hard hard week decided go get happy drink orde...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>extremely suicidal month ago .realized ive rui...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>long terrible relationship going school anxiet...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>specifically yunkai astapor .two city full inn...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2595</th>\n",
              "      <td>im scared .scared .want die want die make sens...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2596</th>\n",
              "      <td>whatever silly mean everything monty python ba...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2597</th>\n",
              "      <td>frozen e menace pour le royaumela franchise de...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2598</th>\n",
              "      <td>connected iphone using bluetooth everything se...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2599</th>\n",
              "      <td>basically life feel like .feel tired foggy unm...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2600 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               sentence  labels\n",
              "0     anxiety right going away . . .work eat . . .wo...       0\n",
              "1     hard hard week decided go get happy drink orde...       0\n",
              "2     extremely suicidal month ago .realized ive rui...       1\n",
              "3     long terrible relationship going school anxiet...       0\n",
              "4     specifically yunkai astapor .two city full inn...       0\n",
              "...                                                 ...     ...\n",
              "2595  im scared .scared .want die want die make sens...       0\n",
              "2596  whatever silly mean everything monty python ba...       0\n",
              "2597  frozen e menace pour le royaumela franchise de...       0\n",
              "2598  connected iphone using bluetooth everything se...       0\n",
              "2599  basically life feel like .feel tired foggy unm...       0\n",
              "\n",
              "[2600 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "LkqFTLWj_xLO",
        "outputId": "9201f7b2-d79d-4ba2-d0e9-b3bb5f14128f"
      },
      "source": [
        "data.loc[data.labels == 0].sample(5)[['sentence', 'labels']]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1083</th>\n",
              "      <td>bought pair headphone exactly day ago used aro...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>mean good film yet one talk .ive seen much wor...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>486</th>\n",
              "      <td>tldr bottom .month still hurt .friend .call b ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2330</th>\n",
              "      <td>there many thing life make happy . . . .gone ....</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1912</th>\n",
              "      <td>pretty great shallow insight life .interesting...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               sentence  labels\n",
              "1083  bought pair headphone exactly day ago used aro...       0\n",
              "90    mean good film yet one talk .ive seen much wor...       0\n",
              "486   tldr bottom .month still hurt .friend .call b ...       0\n",
              "2330  there many thing life make happy . . . .gone ....       0\n",
              "1912  pretty great shallow insight life .interesting...       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cenz2amA_2EG"
      },
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "sentences = data.sentence.values\n",
        "labels = data.labels.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "18dc4e48b6a84761bba835e0d381c024",
            "b1d98bb5e854474bb8656a719bfdf78d",
            "52c748f41807486db079ef5d3b7ec7c7",
            "69104c4f5bbe4a818964e05f29493b5e",
            "f35ed61ebc44450abe4a96457bad026a",
            "6f1493d50bf04a0b8b23d1171010fdfd",
            "cc0ee68cd16c4d5fbb800dd0fcec6c7c",
            "60b5049785ef4f94b09ceb05da7a79ea"
          ]
        },
        "id": "f2tCJnKl_4lm",
        "outputId": "5db62c57-5ab1-4223-ca7e-a6accf26010d"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "18dc4e48b6a84761bba835e0d381c024",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fO5LlxWn_7Oi",
        "outputId": "be4435fd-0682-4adf-cc02-9b533ee8dccd"
      },
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  anxiety right going away . . .work eat . . .worried getting sick ..\n",
            "Tokenized:  ['anxiety', 'right', 'going', 'away', '.', '.', '.', 'work', 'eat', '.', '.', '.', 'worried', 'getting', 'sick', '.', '.']\n",
            "Token IDs:  [10089, 2157, 2183, 2185, 1012, 1012, 1012, 2147, 4521, 1012, 1012, 1012, 5191, 2893, 5305, 1012, 1012]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVjL3CDx_-G9",
        "outputId": "5a6e99ac-8307-438c-d019-9e0d9396e685"
      },
      "source": [
        "max_len = 0\n",
        "for sent in sentences:\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "print('Max sentence length: ', max_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (587 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  2347\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dew4okqyAA2q",
        "outputId": "a36a2408-ff91-4a59-d972-463545c2ff6b"
      },
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "for sent in sentences:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 64,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2155: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:  anxiety right going away . . .work eat . . .worried getting sick ..\n",
            "Token IDs: tensor([  101, 10089,  2157,  2183,  2185,  1012,  1012,  1012,  2147,  4521,\n",
            "         1012,  1012,  1012,  5191,  2893,  5305,  1012,  1012,   102,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlM2Jo6zAD-Q",
        "outputId": "078afe63-a32d-4f6f-8275-ccec5aae0a03"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2,080 training samples\n",
            "  520 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWuEDlPmAHCJ"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0ec9604b63ed49ec98d8e3727ab5da00",
            "5dbe13ade9d84e259ae2e1efe7ba7aa1",
            "71418db7c9594c3a850bd41a49e391e6",
            "bed27af1d115470e9e2d85633e4c1ad0",
            "73b575db802f43cc829f36f8e16a5bbf",
            "a763952721ba4fb9846a26432e6a2f8a",
            "11f9d431fe004b179351e78ac35ca147",
            "7f3ba99dc0444f6a92d7355153a6e978",
            "5b1c586150044586833c17dd987070cd",
            "8a9a56308c524038b86dada8fd2b6aa0",
            "c8a00553362a4001a84120689c9196d0",
            "fcfb776c97dc4f189977bbc412fbb5ce",
            "b896efaf7de747439316e093ab16d81d",
            "5bb5b86bcbe345f88e2f83af101abd6e",
            "29de9f624c3c47538361c94526a7aee3",
            "d39719363a80471fafac2adff9450ecd"
          ]
        },
        "id": "Fvhe-4_1AKSw",
        "outputId": "3868c582-98c9-4543-bcbf-b0034d2d88bd"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0ec9604b63ed49ec98d8e3727ab5da00",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5b1c586150044586833c17dd987070cd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCjvZVM0ANxM",
        "outputId": "aaf3f588-6896-4eeb-90ca-c69a05a3701d"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1LpqBrPATOs"
      },
      "source": [
        "\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKJg8tOoAWAF"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "epochs = 100\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aV59epa8AYed"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRl7Zv6rAbFn"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8u4FbN5AdtJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a89f3463-5ae2-4323-ac13-f4375b486afd"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "training_stats = []\n",
        "total_t0 = time.time()\n",
        "for epoch_i in range(0, epochs):\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        " \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "\n",
        "        model.zero_grad()        \n",
        "        result = model(b_input_ids, \n",
        "                       token_type_ids=None, \n",
        "                       attention_mask=b_input_mask, \n",
        "                       labels=b_labels,\n",
        "                       return_dict=True)\n",
        "\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "\n",
        "        with torch.no_grad():        \n",
        "\n",
        "\n",
        "            result = model(b_input_ids, \n",
        "                           token_type_ids=None, \n",
        "                           attention_mask=b_input_mask,\n",
        "                           labels=b_labels,\n",
        "                           return_dict=True)\n",
        "\n",
        "\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     65.    Elapsed: 0:00:09.\n",
            "\n",
            "  Average training loss: 0.63\n",
            "  Training epcoh took: 0:00:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.74\n",
            "  Validation Loss: 0.58\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     65.    Elapsed: 0:00:09.\n",
            "\n",
            "  Average training loss: 0.45\n",
            "  Training epcoh took: 0:00:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.51\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     65.    Elapsed: 0:00:09.\n",
            "\n",
            "  Average training loss: 0.34\n",
            "  Training epcoh took: 0:00:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.52\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     65.    Elapsed: 0:00:09.\n",
            "\n",
            "  Average training loss: 0.27\n",
            "  Training epcoh took: 0:00:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.79\n",
            "  Validation Loss: 0.55\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:00:59 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mED-894v9xN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgQ4VfOlAhjz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "e05a2992-2cc1-4d8d-bf22-e095f594a28e"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "df_stats"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.63</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0:00:14</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.45</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.78</td>\n",
              "      <td>0:00:14</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.34</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.78</td>\n",
              "      <td>0:00:14</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.27</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0:00:14</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.63         0.58           0.74       0:00:14         0:00:01\n",
              "2               0.45         0.51           0.78       0:00:14         0:00:01\n",
              "3               0.34         0.52           0.78       0:00:14         0:00:01\n",
              "4               0.27         0.55           0.79       0:00:14         0:00:01"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oxcHnk_AlWO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "3efd3374-dd8f-42e6-ca87-efdf2563a45c"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "import seaborn as sns\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUEtVRIUAoWF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "3e91130e-a7a1-4312-a9e1-33b0c22577d2"
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>anxiety right going away . . .work eat . . .wo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hard hard week decided go get happy drink orde...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>extremely suicidal month ago .realized ive rui...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>long terrible relationship going school anxiet...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>specifically yunkai astapor .two city full inn...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2595</th>\n",
              "      <td>im scared .scared .want die want die make sens...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2596</th>\n",
              "      <td>whatever silly mean everything monty python ba...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2597</th>\n",
              "      <td>frozen e menace pour le royaumela franchise de...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2598</th>\n",
              "      <td>connected iphone using bluetooth everything se...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2599</th>\n",
              "      <td>basically life feel like .feel tired foggy unm...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2600 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               sentence  labels\n",
              "0     anxiety right going away . . .work eat . . .wo...       0\n",
              "1     hard hard week decided go get happy drink orde...       0\n",
              "2     extremely suicidal month ago .realized ive rui...       1\n",
              "3     long terrible relationship going school anxiet...       0\n",
              "4     specifically yunkai astapor .two city full inn...       0\n",
              "...                                                 ...     ...\n",
              "2595  im scared .scared .want die want die make sens...       0\n",
              "2596  whatever silly mean everything monty python ba...       0\n",
              "2597  frozen e menace pour le royaumela franchise de...       0\n",
              "2598  connected iphone using bluetooth everything se...       0\n",
              "2599  basically life feel like .feel tired foggy unm...       0\n",
              "\n",
              "[2600 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7cV5GouAqxs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0716593e-59d8-47a1-ccf7-efc50a5a5d49"
      },
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased',\n",
        "                                     num_labels = 2,\n",
        "                                     output_attentions = False,\n",
        "                                     output_hidden_states =  False)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeFBpSQ0v0Rw",
        "outputId": "d083891c-3356-4e57-f290-eca245032b21"
      },
      "source": [
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13o2wgtfwIc1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAGXsABxwImx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdp5WjM8wIrC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}